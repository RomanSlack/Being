# Summary: Metrical-Tracker Preprocessing Investigation

## Questions Asked

1. Does metrical-tracker crop to face region? If so, how does it determine the crop box?
2. Does it store the crop coordinates anywhere in its output?
3. What is the input image format/size it expects?
4. Can we reconstruct the crop box from the camera intrinsics (K matrix)?

## Answers

### Question 1: Cropping Strategy
**Yes, it crops.** Default config: `crop_image = True`

Pipeline:
```
Original video (1920x1080)
  -> Extract frames @ 25fps
  -> Face detection on frame 0 (face_alignment library)
  -> Landmark extraction
  -> Compute bounding box from landmarks
  -> Apply scale factor (default bb_scale=2.5)
  -> Crop all frames with same bbox
  -> Pad to square (if needed)
  -> Resize to 512x512
```

The bounding box is:
- **Square** (centered on face, side = max(dx, dy))
- **Computed from 68-point face landmarks** (face_alignment)
- **Scaled by bb_scale factor** for padding around face
- **Clamped to image bounds**

### Question 2: Storage of Crop Coordinates

**NOT stored in .frame files**, but **IS saved to bbox.pt**

Files involved:
- `bbox.pt`: Contains `[xb_min, xb_max, yb_min, yb_max]` in original image coordinates
- `.frame` files: Contain K, R, t, FLAME params, but NOT crop box
- K matrix: Always relative to the **512x512 cropped image**

**Critical implication:** All camera parameters in .frame files are for the cropped+resized 512x512 image, not the original video.

### Question 3: Input Format/Size Expectations

Input:
- **Accepts:** MP4 video or pre-extracted image sequence
- **Resolution:** Any (uses original, then crops)
- **Extraction:** `ffmpeg -i video.mp4 -vf fps=25 -q:v 1 output/%05d.png`
- **Quality:** Highest (q:v 1)

Output (stored):
- **Size:** 512x512 (configurable as `image_size`)
- **Format:** PNG images + .frame checkpoints
- **Landmarks:** Rescaled to 512x512 space

### Question 4: Reconstructing Crop from K Matrix

**Not directly from K matrix alone.** But:

1. **If bbox.pt exists:** Use it directly
   ```python
   bbox = torch.load('bbox.pt')
   xb_min, xb_max, yb_min, yb_max = bbox
   ```

2. **If bbox.pt is lost:** Can approximately recover if you have original and cropped images, but transformation is lossy

3. **Transform K back to original image:**
   ```python
   K_original[0, 2] = K_512[0, 2] + xb_min
   K_original[1, 2] = K_512[1, 2] + yb_min
   # Focal length unchanged
   K_original[0, 0] = K_512[0, 0]
   K_original[1, 1] = K_512[1, 1]
   ```

## Key Insights

1. **Focal length is invariant to cropping:** K[0,0] and K[1,1] stay the same, only principal point shifts

2. **Principal point in K is relative to image center:** Your K shows (255, 250) for 512x512, almost perfectly centered at (256, 256) - face is centered in crop

3. **Transformation is partially lossy:**
   - Crop box can be recovered from bbox.pt (not lossy)
   - Padding constants not stored (but usually just black borders)
   - Resize is lossy (INTER_CUBIC downsampling)

4. **Your data:** With K = [[2339, 0, 255], [0, 2339, 250], [0, 0, 1]]:
   - Very high focal length (12.5 degree FOV) - face is zoomed in
   - Face is perfectly centered in the crop
   - The original crop was likely ~800x800 or similar

5. **metrical-tracker design philosophy:**
   - Separates "source" (original), "input/kpt" (landmarks), and "images" (processed) directories
   - Reuses same bbox across entire sequence for consistency
   - Doesn't need to store bbox in .frame files because it's preserved in filesystem

## Files Created

1. **Main Analysis:** `/home/roman/Being/notes/2026-02-25-metrical_tracker_preprocessing.md`
   - Complete code walkthrough
   - Full explanation of each step
   - How to recover crop and transform K

2. **Crop Recovery Guide:** `/home/roman/Being/notes/2026-02-25-crop_recovery_guide.md`
   - Practical steps for YOUR specific data
   - How to use bbox.pt
   - How to transform K for 1920x1080
   - Next steps for GaussianTalker Round 2

3. **Visual Transformation Guide:** `/home/roman/Being/notes/2026-02-25-crop_transformation_diagram.md`
   - Visual diagrams of the pipeline
   - Coordinate system transformations
   - Camera matrix math explained
   - Why we can't recover exact padding

4. **Helper Script:** `/home/roman/Being/scripts/recover_metrical_tracker_crop.py`
   - Load and analyze .frame files
   - Transform K matrices
   - Estimate crop information
   - Analyze intrinsics

5. **This Summary:** You're reading it!

## Actionable Next Steps

For your GaussianTalker Round 2 work:

1. **Locate bbox.pt** in `/workspace/Being/extern/GaussianTalker/` or pod backup
2. **Load it** and verify the crop coordinates
3. **Transform K matrix** for original 1920x1080 resolution
4. **Decide on resolution:**
   - Keep 512x512: Works, but limited facial detail
   - Re-run with larger crop: 768x768 or 1024x1024
   - Use original video: Best quality, requires full re-tracking
5. **Enable full-face tracking:**
   - `optimize_shape: true` and `optimize_jaw: true` in config
   - Ensure all 478 MediaPipe landmarks are used
   - Not just mouth tracking like FlashAvatar

## Key Code Locations

In metrical-tracker repo (`/tmp/metrical-tracker/`):
- **Bbox calculation:** `image.py:22-42` (get_bbox function)
- **Cropping pipeline:** `datasets/generate_dataset.py:49-93` (GeneratorDataset.run)
- **Camera calibration:** `tracker.py:376-427` (optimize_camera)
- **Checkpoint saving:** `tracker.py:183-225` (save_checkpoint)
- **Config:** `configs/config.py` (all parameters)

In INSTA repo (`/tmp/INSTA/`):
- **Data conversion:** `scripts/transforms.py:53-87` (dump_intrinsics, dump_frame)
- Shows how INSTA uses metrical-tracker output

## Conclusion

Metrical-tracker's cropping is **well-designed but not fully documented**. The key is understanding that:

1. Crop box is saved to **bbox.pt** (filesystem-level, not in .frame)
2. K matrix in .frame files is **for 512x512 only**
3. Recovery requires **bbox.pt + simple arithmetic transformation**
4. Process is **partially lossy** (resampling, padding) but **functionally complete**

With bbox.pt, you can perfectly transform intrinsics back to original image space and use tracking data with full-resolution rendering.
